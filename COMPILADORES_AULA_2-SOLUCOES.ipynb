{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMPILADORES-AULA 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwxHf3E81Qyz"
      },
      "source": [
        "**COMPILADORES - AULA 2**\n",
        "\n",
        "***Prof. Luciano Silva***\n",
        "\n",
        "**Objetivos da aula:**\n",
        "*   revisar implementação de analisadores léxicos em rply\n",
        "*   analisar a grmática da linguagem TINY-C\n",
        "*   implementar um analisador léxico para TINY-C\n",
        "*   aumentar a gramática da TINY-C e imlementar um analisador léxico para isto\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGMxqj9y7vWS"
      },
      "source": [
        "**REVISÃO - AULA ANTERIOR**\n",
        "\n",
        "Queremos constuir um analisador léxico para os símbolos terminais da gramática abaixo:\n",
        "\n",
        "\\<expression\\> ::= NUMBER\n",
        "\n",
        "               | \\<expression\\> \"+\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"-\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"*\" \\<expression\\>\n",
        "\n",
        "               | \\<expression\\> \"/\" \\<expression\\>\n",
        "\n",
        "               | \"(\" <expression> \")\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdlT1XbX8PFb"
      },
      "source": [
        "O primeiro passo é instalar o rply, um módulo para construir analisadores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbWUx55j1tLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4461ce04-7c9a-464d-fdf5-b0c4cb01a900"
      },
      "source": [
        "!pip install rply"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rply\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/7c/f66be9e75485ae6901ae77d8bdbc3c0e99ca748ab927b3e18205759bde09/rply-0.7.8-py2.py3-none-any.whl\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from rply) (1.4.4)\n",
            "Installing collected packages: rply\n",
            "Successfully installed rply-0.7.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQEvnI9-9S-n"
      },
      "source": [
        "Toda a documentação do rply pode ser encontrada abaixo:\n",
        "\n",
        "<a href=\"https://rply.readthedocs.io/en/latest/\">Documentação RPLY </a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdp5ClkZ98Tw"
      },
      "source": [
        "O segundo passo é construir o analisador léxico:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rezf3OAt1P7_"
      },
      "source": [
        "from rply import LexerGenerator\n",
        "\n",
        "lg = LexerGenerator()\n",
        "\n",
        "lg.add('NUMBER', r'\\d+')\n",
        "lg.add('PLUS', r'\\+')\n",
        "lg.add('MINUS', r'-')\n",
        "lg.add('MUL', r'\\*')\n",
        "lg.add('DIV', r'/')\n",
        "lg.add('OPEN_PARENS', r'\\(')\n",
        "lg.add('CLOSE_PARENS', r'\\)')\n",
        "\n",
        "lg.ignore('\\s+')\n",
        "\n",
        "lexer = lg.build()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gxpqmaf9khR"
      },
      "source": [
        "Observe que, associado a cada classe léxica, temos uma expressão regular associada. Esta expressão regular usa a facilidade RegEx do Python, cuja documentação pode ser enontrada abaixo:\n",
        "\n",
        "<a href=\"https://blog.geekhunter.com.br/python-regex/\"> Expressões Regulares em Python </a>\n",
        "\n",
        "Para usar somente o analisador léxico, podemos usar o código abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CrRKNZi9vMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fdda91-749f-4934-80a9-32199becbb77"
      },
      "source": [
        "for token in lexer.lex('1+1-1'):\n",
        "  print(token)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token('NUMBER', '1')\n",
            "Token('PLUS', '+')\n",
            "Token('NUMBER', '1')\n",
            "Token('MINUS', '-')\n",
            "Token('NUMBER', '1')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbZuGJ8r2dSg"
      },
      "source": [
        "**LINGUAGEM TINY-C**\n",
        "\n",
        "Abaixo temos a gramática (livre de contexto) da linguagem TINY-C, um subconjunto bastante expressivo da linguagem C:\n",
        "\n",
        "<i>\n",
        "Smallc_program ::= type_specifier id ‘(‘ param_decl_list ‘)’ compound_stmt\n",
        "\n",
        "Type_specifier ::= int | char\n",
        "\n",
        "Param_decl_list ::= parameter_decl (‘,’ parameter_decl )*\n",
        "\n",
        "Param_decl ::= type_specifier id\n",
        "\n",
        "Compound_stmt ::= ‘{‘ (var_decl* stmt*)? ‘}’\n",
        "\n",
        "Var_decl ::= type_specifier var_decl_list ‘;’ \n",
        "\n",
        "Var_decl_list ::= variable_id ( ‘,’ variable_id)*\n",
        "\n",
        "Variable_id ::= id ( ‘=’ expr )?\n",
        "\n",
        "Stmt ::= compound_stmt | cond_stmt | while_stmt | break ‘;’ | continue ‘;’ | return expr ‘;’ | readint ‘(‘ id ‘)’ ‘;’ |\n",
        " writeint ‘(‘ expr ‘)’ ‘;’\n",
        "\n",
        "Cond_stmt ::= if ‘(‘ expr ‘)’ stmt (else stmt)?\n",
        "\n",
        "While_stmt ::= while ‘(‘ expr ‘)’ stmt\n",
        "\n",
        "Expr ::= id ‘=’ expr | condition\n",
        "\n",
        "Condition ::= disjunction | disjunction ‘?’ expr ‘:’ condition\n",
        "\n",
        "Disjunction ::= conjunction | disjunction ‘||’ conjunction\n",
        "\n",
        "Conjunction ::= comparison | conjunction ‘&&’ comparison\n",
        "\n",
        "Comparison ::= relation | relation ‘==’ relation\n",
        "\n",
        "Relation ::= sum | sum (‘<’ | ‘>’) sum\n",
        "\n",
        "Sum ::= sum ‘+’ term | sum ‘-’ term | term\n",
        "\n",
        "Term ::= term ‘*’ factor | term ‘/’ factor | term ‘%’ factor | factor\n",
        "\n",
        "Factor ::= ‘!’ factor | ‘-’ factor | primary\n",
        "\n",
        "Primary ::= num | charconst | id | ‘(‘ expr ‘)’\n",
        "</i> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPM4_Jpf3SGP"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Escreva um programa na linguagem TINY-C:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHTZVpl63tla"
      },
      "source": [
        "int soma(int a,int b){\n",
        "\n",
        "  int s;\n",
        "\n",
        "  s=a+b;\n",
        "\n",
        "  return s;\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6URuPQaL4D8j"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Escreva um analisador léxico para a gramática acima."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHY05GN54P9t"
      },
      "source": [
        "from rply import LexerGenerator\n",
        "\n",
        "lg = LexerGenerator()\n",
        "\n",
        "lg.add('INT', r'int')\n",
        "lg.add('CHAR', r'char')\n",
        "lg.add('BREAK', r'break')\n",
        "lg.add('CONTINUE', r'continue')\n",
        "lg.add('RETURN', r'return')\n",
        "lg.add('READINT', r'readint')\n",
        "lg.add('WRITEINT', r'writeint')\n",
        "lg.add('IF', r'if')\n",
        "lg.add('WHILE', r'while')\n",
        "lg.add('ID', r'[a-zA-Z][a-zA-Z0-9]*')\n",
        "lg.add('OPEN_PAR', r'\\(')\n",
        "lg.add('CLOSE_PAR', r'\\)')\n",
        "lg.add('VIRG', r'\\,')\n",
        "lg.add('OPEN_CH', r'\\{')\n",
        "lg.add('CLOSE_CH', r'\\}')\n",
        "lg.add('PVIRG', r'\\;')\n",
        "lg.add('COMPEQUALS', r'==')\n",
        "lg.add('COMPMAIOR', r'\\>')\n",
        "lg.add('COMPMENOR', r'\\<')\n",
        "lg.add('EQUALS', r'=')\n",
        "lg.add('INTERROG', r'\\?')\n",
        "lg.add('DOISP', r'\\:')\n",
        "lg.add('DISJ', r'\\|\\|')\n",
        "lg.add('CONJ', r'&&')\n",
        "lg.add('NOT', r'\\!')\n",
        "\n",
        "lg.add('NUMBER', r'[+-]?\\d+')\n",
        "lg.add('CHARCONST', r'\\'\\S\\'')\n",
        "lg.add('PLUS', r'\\+')\n",
        "lg.add('MINUS', r'-')\n",
        "lg.add('MUL', r'\\*')\n",
        "lg.add('DIV', r'/')\n",
        "lg.add('MOD', r'\\%')\n",
        "\n",
        "lg.ignore('\\s+')\n",
        "\n",
        "lexer = lg.build()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QeqnWD94j2E"
      },
      "source": [
        "**EXERCÍCIO PROPOSTO**\n",
        "\n",
        "Aplique seu analisador léxico para quebrar em tokens o seu programa escrito em TINY-C:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmQxwqVA4wgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0deead-8665-4543-dc41-3e9fdaf5845e"
      },
      "source": [
        "for token in lexer.lex('int soma(int a,int b){int s;s=a+b;return s;}'):\n",
        "  print(token)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token('INT', 'int')\n",
            "Token('ID', 'soma')\n",
            "Token('OPEN_PAR', '(')\n",
            "Token('INT', 'int')\n",
            "Token('ID', 'a')\n",
            "Token('VIRG', ',')\n",
            "Token('INT', 'int')\n",
            "Token('ID', 'b')\n",
            "Token('CLOSE_PAR', ')')\n",
            "Token('OPEN_CH', '{')\n",
            "Token('INT', 'int')\n",
            "Token('ID', 's')\n",
            "Token('PVIRG', ';')\n",
            "Token('ID', 's')\n",
            "Token('EQUALS', '=')\n",
            "Token('ID', 'a')\n",
            "Token('PLUS', '+')\n",
            "Token('ID', 'b')\n",
            "Token('PVIRG', ';')\n",
            "Token('RETURN', 'return')\n",
            "Token('ID', 's')\n",
            "Token('PVIRG', ';')\n",
            "Token('CLOSE_CH', '}')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as3YFA_m-KTm"
      },
      "source": [
        "**ATIVIDADE EAD**\n",
        "\n",
        "\n",
        "1.   Aumentar as regras de sua gramática para incluir mais de uma função por programa\n",
        "2.   Aumentar as regras de sua gramática para incluir definição de vetores no estilo C  (Exemplo: int v[10];)\n",
        "3.   Implementar um analisador léxico para incluir as duas novas regras acima\n",
        "4.   Escrever um programa em TINY-C (com as novas regras acima) e fazer sua análise léxica com  o analisador do item (3).\n",
        "\n",
        "**O que entregar:** notebook contendo os programas em Python\n",
        "\n"
      ]
    }
  ]
}